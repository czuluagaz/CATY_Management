{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast Consumption\n",
    "\n",
    "Forecasting using timeseries model the consumption of water, gas and electricity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import sys\n",
    "# import pandas as pd\n",
    "\n",
    "# sys.path.append(str(Path.cwd().parents[0]))\n",
    "# from core.data_manager import read_data_csv_df\n",
    "\n",
    "\n",
    "# # function to read the data\n",
    "# def read_data_csv_df(directory: str, filename: str) -> pd.DataFrame:\n",
    "#     path=Path.cwd().parents[0]\n",
    "#     try:\n",
    "#         df = pd.read_csv(path.joinpath(directory,filename))\n",
    "#         return df\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"File {filename} not found\")\n",
    "#         print(\"Please verify the file name and try again, and path\")\n",
    "#         exit()\n",
    "\n",
    "# df = read_data_csv_df(\"data_storage\", \"resampled_data_D_gas.csv\")\n",
    "\n",
    "\n",
    "# \"data_storage\", \"resampled_data_D_gas.csv\"\n",
    "\n",
    "# df = pd.read_csv(path.joinpath(\"data_storage\",\"resampled_data_D_gas.csv\"))\n",
    "# df.columns\n",
    "# print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# sys.path.append('../../')\n",
    "# from core.settings import gas_monthly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "\n",
    "\n",
    "path = Path.cwd().parents[0]\n",
    "\n",
    "\n",
    "# gas_daily_df = pd.read_csv(path.joinpath(\"data_storage\",\"resampled_data_D_gas.csv\"))\n",
    "# water_daily_df = pd.read_csv(path.joinpath(\"data_storage\",\"resampled_data_D_water.csv\"))\n",
    "power_daily_df = pd.read_csv(\n",
    "    path.joinpath(\"data_storage\", \"resampled_data_D_power.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gas_daily_df.info()\n",
    "# # gas_monthly_df.describe()\n",
    "\n",
    "power_daily_df.info()\n",
    "# power_monthly_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show duplicate dates in the data\n",
    "power_daily_df[power_daily_df.duplicated(subset=[\"date\"], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by date\n",
    "power_daily_df.sort_values(by=[\"date\"], inplace=True)\n",
    "# show date 2021-04-01\n",
    "power_daily_df[power_daily_df[\"date\"] < \"2021-04-03\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(power_daily_df.head())\n",
    "# Dealing with missing values\n",
    "# # show NaN values rows\n",
    "# gas_monthly_df[gas_monthly_df.isnull().any(axis=1)]\n",
    "\n",
    "# # show duplicate rows\n",
    "# gas_monthly_df[gas_monthly_df.duplicated()]\n",
    "\n",
    "# # show rows for date 2014-09-04\n",
    "# gas_monthly_df[gas_monthly_df['date'] == '2014-09-04']\n",
    "\n",
    "# agregate by id_meter, date\n",
    "power_daily_df = power_daily_df.groupby([\"id_meter\", \"date\"]).agg(\"sum\").reset_index()\n",
    "\n",
    "# agregate by date, if id_meter is the same, sum the values, else keep both values\n",
    "power_daily_df = (\n",
    "    power_daily_df.groupby([\"date\"])\n",
    "    .agg(\n",
    "        {\n",
    "            \"calc_cons\": \"sum\",\n",
    "            \"id_meter\": lambda x: \", \".join(map(str, x)),\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# in the column id_meter, keep only one value\n",
    "power_daily_df[\"id_meter\"] = power_daily_df[\"id_meter\"].apply(lambda x: x.split(\",\")[0])\n",
    "\n",
    "# convert id_meter to float\n",
    "power_daily_df[\"id_meter\"] = power_daily_df[\"id_meter\"].astype(float)\n",
    "\n",
    "# # in the column id_meter, keep only the value that is last in the list\n",
    "# power_daily_df[\"id_meter\"] = power_daily_df[\"id_meter\"].apply(\n",
    "#     lambda x: x.split(\",\")[-1]\n",
    "# )\n",
    "# # remove empty spaces in the column id_meter\n",
    "# power_daily_df[\"id_meter\"] = power_daily_df[\"id_meter\"].str.strip()\n",
    "\n",
    "# fill row 0 NaN value with 0\n",
    "power_daily_df = power_daily_df.fillna(0, inplace=False)\n",
    "\n",
    "# drop duplicate rows keeping the last row\n",
    "power_daily_df.drop_duplicates(subset=[\"date\"], keep=\"last\", inplace=True)\n",
    "\n",
    "# # show duplicate dates rows\n",
    "# gas_monthly_df[gas_monthly_df.duplicated(['date'])]\n",
    "\n",
    "# # # drop duplicate dates rows\n",
    "# # gas_monthly_df.drop_duplicates(subset=['date'], inplace=False)\n",
    "\n",
    "# convert date column to datetime\n",
    "power_daily_df[\"date\"] = pd.to_datetime(power_daily_df[\"date\"])\n",
    "\n",
    "\n",
    "power_daily_df.info()\n",
    "\n",
    "# # verify that there are not missing dates in the data\n",
    "# gas_monthly_df['date'] = pd.to_datetime(gas_monthly_df['date'])\n",
    "# gas_monthly_df['date'].diff().dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns not columns 1 to 3\n",
    "# gas_daily_df = gas_daily_df.drop(gas_daily_df.columns[1:3], axis=1, inplace=False)\n",
    "\n",
    "power_daily_df.head()\n",
    "\n",
    "# unique values in id_meter column\n",
    "power_daily_df[\"id_meter\"].unique()\n",
    "\n",
    "# # show values with id_meter == 11\n",
    "# power_daily_df[power_daily_df['id_meter'] == 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show 0 values in calc_cons column\n",
    "power_daily_df[power_daily_df[\"calc_cons\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show duplicate dates rows\n",
    "power_daily_df[power_daily_df.duplicated([\"date\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert date column to datetime\n",
    "# power_daily_df[\"date\"] = pd.to_datetime(power_daily_df[\"date\"])\n",
    "# # set date column as index\n",
    "# power_daily_df.set_index(\"date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by date\n",
    "power_daily_df = power_daily_df.sort_values(by=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_daily_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_daily_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # subsample the data to hourly\n",
    "# gas_hourly_df = gas_daily_df.resample('h').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list with the column defined by position 1, 2 in the axis 1\n",
    "plot_cols = power_daily_df.columns[1:2]\n",
    "plot_features = power_daily_df[plot_cols]\n",
    "plot_features.index = power_daily_df.index\n",
    "_ = plot_features.plot(subplots=True)\n",
    "\n",
    "plot_features = power_daily_df[plot_cols][:168]\n",
    "plot_features.index = power_daily_df.index[:168]\n",
    "_ = plot_features.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featured ingeenering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert time\n",
    "# convert date to seconds to made it more readable\n",
    "power_daily_df[\"date\"] = pd.to_datetime(power_daily_df[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming daily, weekly, monthly, yearly perioditicity\n",
    "# daily\n",
    "power_daily_df[\"day\"] = power_daily_df[\"date\"].dt.day\n",
    "power_daily_df[\"month\"] = power_daily_df[\"date\"].dt.month\n",
    "power_daily_df[\"year\"] = power_daily_df[\"date\"].dt.year\n",
    "power_daily_df[\"dayofweek\"] = power_daily_df[\"date\"].dt.dayofweek\n",
    "power_daily_df[\"dayofyear\"] = power_daily_df[\"date\"].dt.dayofyear\n",
    "# power_daily_df[\"week\"] = power_daily_df[\"date\"].dt.week\n",
    "power_daily_df[\"quarter\"] = power_daily_df[\"date\"].dt.quarter\n",
    "\n",
    "# # weekly\n",
    "# power_daily_df[\"week\"] = power_daily_df[\"date\"].dt.week\n",
    "\n",
    "# monthly\n",
    "power_daily_df[\"month\"] = power_daily_df[\"date\"].dt.month\n",
    "\n",
    "# yearly\n",
    "power_daily_df[\"year\"] = power_daily_df[\"date\"].dt.year\n",
    "\n",
    "# show the first rows\n",
    "power_daily_df.head()\n",
    "\n",
    "# plot the data\n",
    "plt.plot(np.array(power_daily_df[\"date\"]), np.array(power_daily_df[\"calc_cons\"]))\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Consumption\")\n",
    "plt.title(\"Power consumption\")\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(np.array(power_daily_df[\"day\"]), np.array(power_daily_df[\"calc_cons\"]))\n",
    "# plt.xlabel(\"Day\")\n",
    "# plt.ylabel(\"Consumption\")\n",
    "# plt.title(\"Power consumption\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using cosine and sine to encode the cyclical nature of time\n",
    "# day\n",
    "power_daily_df[\"day_sin\"] = np.sin(power_daily_df[\"day\"] * (2 * np.pi / 31))\n",
    "power_daily_df[\"day_cos\"] = np.cos(power_daily_df[\"day\"] * (2 * np.pi / 31))\n",
    "# month\n",
    "power_daily_df[\"month_sin\"] = np.sin(power_daily_df[\"month\"] * (2 * np.pi / 12))\n",
    "power_daily_df[\"month_cos\"] = np.cos(power_daily_df[\"month\"] * (2 * np.pi / 12))\n",
    "# year\n",
    "power_daily_df[\"year_sin\"] = np.sin(power_daily_df[\"year\"] * (2 * np.pi / 2021))\n",
    "power_daily_df[\"year_cos\"] = np.cos(power_daily_df[\"year\"] * (2 * np.pi / 2021))\n",
    "# dayofweek\n",
    "power_daily_df[\"dayofweek_sin\"] = np.sin(power_daily_df[\"dayofweek\"] * (2 * np.pi / 7))\n",
    "power_daily_df[\"dayofweek_cos\"] = np.cos(power_daily_df[\"dayofweek\"] * (2 * np.pi / 7))\n",
    "# dayofyear\n",
    "power_daily_df[\"dayofyear_sin\"] = np.sin(\n",
    "    power_daily_df[\"dayofyear\"] * (2 * np.pi / 366)\n",
    ")\n",
    "power_daily_df[\"dayofyear_cos\"] = np.cos(\n",
    "    power_daily_df[\"dayofyear\"] * (2 * np.pi / 366)\n",
    ")\n",
    "# quarter\n",
    "power_daily_df[\"quarter_sin\"] = np.sin(power_daily_df[\"quarter\"] * (2 * np.pi / 4))\n",
    "power_daily_df[\"quarter_cos\"] = np.cos(power_daily_df[\"quarter\"] * (2 * np.pi / 4))\n",
    "\n",
    "# # show the first rows\n",
    "power_daily_df.head()\n",
    "\n",
    "plt.plot(np.array(power_daily_df[\"day_sin\"])[:31])\n",
    "plt.plot(np.array(power_daily_df[\"day_cos\"])[:31])\n",
    "plt.xlabel(\"Time [days]\")\n",
    "plt.title(\"Time of day signal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast Fourier Transform???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "# split the data into train, validation, and test set\n",
    "# train set is 70% of the data\n",
    "# validation set is 15% of the data\n",
    "# test set is 15% of the data\n",
    "n = len(power_daily_df)\n",
    "train_df = power_daily_df[0 : int(n * 0.7)]\n",
    "val_df = power_daily_df[int(n * 0.7) : int(n * 0.85)]\n",
    "test_df = power_daily_df[int(n * 0.85) :]\n",
    "# check the length of the data\n",
    "print(len(train_df), len(val_df), len(test_df))\n",
    "\n",
    "num_features = power_daily_df.shape[1]\n",
    "\n",
    "print(f\"Number of features = {num_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "# normalize the data using the mean and standard deviation of the training data\n",
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "\n",
    "train_df = (train_df - train_mean) / train_std\n",
    "val_df = (val_df - train_mean) / train_std\n",
    "test_df = (test_df - train_mean) / train_std\n",
    "\n",
    "# # show the first rows\n",
    "train_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
