{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Weather API\n",
    "\n",
    "THis notebook go thru the process to gather the data from an API connection, exported to csv/json for the historical files needed later, create a df for preprocessing, and produce at the end a ready to use data that can be integrated to timeseries_data table of each customer.\n",
    "\n",
    "_Open Weather_:\n",
    "Forecast: It produce forecast in a range of 3h for 160h in the future. A new forecast is made in the model every 10'.\n",
    "Current:\n",
    "\n",
    "Consideerations:\n",
    "1. Call for current weather or forecast weather (historical to populate files will be download in one shoot from server)\n",
    "2. Call 1 site or for multiple sites\n",
    "3. Automatic call with a given interval\n",
    "4. Function that connect the specific site(s) lat/lon from the customer and create the df_lat_lon that will be used for call the API\n",
    "5. Keep a csv historical file to store the progression of the different call\n",
    "6. All the data stored in 1 file\n",
    "7. Parameters to be keeped: \n",
    "    - Main: Temp, Humidity\n",
    "    - Secondary: Rain, Sun_exposure, wind_speed, ground_pressure, forecast\n",
    "8. Preprocess:\n",
    "    \n",
    "    - Create the time frame compatible with the 15 minutes interval in the energy consumption interval = 15'\n",
    "    - Populate the intervals with and linear interpolation of the data from hour x to hour w+new meassure\n",
    "    - Not Nan data\n",
    "    - Rain (m3 of rain per hour) NaN converted to 0\n",
    "    - Keep only the most up to date data (last) records\n",
    "    - ? Specific df with data only for the site(s) that are pertinent for the customer \n",
    "    - ? Store in a dedicated df that will be exported to timeseries_data of the specific project\n",
    "\n",
    "Author: Camilo Zuluaga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'schedule'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mschedule\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'schedule'"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import pathlib\n",
    "import schedule\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables\n",
    "\n",
    "Create connection to data and other sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable path_lat_lon with the path to the CSV file (C:\\Users\\zudel\\projects\\zapdos\\weather_api\\data\\lat_long_cities.csv) with the cities and their coordinates\n",
    "path_lat_lon = \"C:/Users/zudel/projects/zapdos/weather_api/data/lat_long_cities.csv\"\n",
    "\n",
    "# create csv file to save different if is current or forecast\n",
    "path_forecast_csv = \"weather_data_openweather.csv\"\n",
    "path_forecast_data = f\"forecast_data_{path_lat_lon}.csv\"\n",
    "\n",
    "# df_lat_lon with the data of the CSV file\n",
    "df_lat_lon = pd.read_csv(path_lat_lon)\n",
    "\n",
    "# Interval time (up_time) for the update of the call\n",
    "up_time = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables specific to the API (Openweather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API_KEY open weather\n",
    "API_KEY = \"a019bc0712358cb223887c5bf73bb473\"\n",
    "\n",
    "\n",
    "# variable lat, lon Brusselles (testing)\n",
    "lat = \"50.85045\"\n",
    "lon = \"4.34878\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different URL API call (current, forecast)\n",
    "# global variable openweather API \"current weather\"\n",
    "url_current = (\n",
    "    \"https://api.openweathermap.org/data/2.5/weather?lat=\"\n",
    "    + lat\n",
    "    + \"&lon=\"\n",
    "    + lon\n",
    "    + \"&exclude=hourly,minutely&appid=\"\n",
    "    + API_KEY\n",
    "    + \"&units=metric\"\n",
    ")  # current weather & exlude=current\n",
    "\n",
    "\n",
    "# global varaiables open weather api **forecast**\n",
    "url_forecast = (\n",
    "    \"https://api.openweathermap.org/data/2.5/forecast?lat=\"\n",
    "    + lat\n",
    "    + \"&lon=\"\n",
    "    + lon\n",
    "    + \"&appid=\"\n",
    "    + API_KEY\n",
    "    + \"&units=metric\"\n",
    ")  # 5 days forecast 3 hours interval &exclude=current,minutely,hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to store the data in a CSV file\n",
    "# def store_data(data, path):\n",
    "#     # Check if the directory exists, if not, create it\n",
    "#     directory = os.path.dirname(path)\n",
    "#     if not os.path.exists(directory):\n",
    "#         os.makedirs(directory)\n",
    "\n",
    "#     # Save the data to the file\n",
    "#     data.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different functions to call current, forecast\n",
    "\n",
    "Function to create the API connection and verify if is working. Function intended as a control point to deal with connections issueas and create a log if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call the open weather api. Use url_current or url_forecast. Test the connection\n",
    "def call_open_weather_api(url):\n",
    "    # Call the API\n",
    "    response = requests.get(url)\n",
    "    # Check if the response is correct\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None  # print(f\"Error [{response.status_code}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            dt                                               main  \\\n",
      "0   1715774400  {'temp': 16.32, 'feels_like': 16.15, 'temp_min...   \n",
      "1   1715785200  {'temp': 16.8, 'feels_like': 16.55, 'temp_min'...   \n",
      "2   1715796000  {'temp': 16.69, 'feels_like': 16.5, 'temp_min'...   \n",
      "3   1715806800  {'temp': 13.89, 'feels_like': 13.89, 'temp_min...   \n",
      "4   1715817600  {'temp': 13.26, 'feels_like': 13.2, 'temp_min'...   \n",
      "5   1715828400  {'temp': 12.9, 'feels_like': 12.78, 'temp_min'...   \n",
      "6   1715839200  {'temp': 13.65, 'feels_like': 13.53, 'temp_min...   \n",
      "7   1715850000  {'temp': 14.62, 'feels_like': 14.46, 'temp_min...   \n",
      "8   1715860800  {'temp': 14.62, 'feels_like': 14.49, 'temp_min...   \n",
      "9   1715871600  {'temp': 13.26, 'feels_like': 13.1, 'temp_min'...   \n",
      "10  1715882400  {'temp': 12.99, 'feels_like': 12.9, 'temp_min'...   \n",
      "11  1715893200  {'temp': 12.61, 'feels_like': 12.46, 'temp_min...   \n",
      "12  1715904000  {'temp': 12.21, 'feels_like': 12.02, 'temp_min...   \n",
      "13  1715914800  {'temp': 12.06, 'feels_like': 11.83, 'temp_min...   \n",
      "14  1715925600  {'temp': 12.51, 'feels_like': 12.24, 'temp_min...   \n",
      "15  1715936400  {'temp': 15.35, 'feels_like': 15, 'temp_min': ...   \n",
      "16  1715947200  {'temp': 18.78, 'feels_like': 18.23, 'temp_min...   \n",
      "17  1715958000  {'temp': 18.53, 'feels_like': 18.11, 'temp_min...   \n",
      "18  1715968800  {'temp': 16.7, 'feels_like': 16.46, 'temp_min'...   \n",
      "19  1715979600  {'temp': 13.18, 'feels_like': 12.9, 'temp_min'...   \n",
      "20  1715990400  {'temp': 12.79, 'feels_like': 12.47, 'temp_min...   \n",
      "21  1716001200  {'temp': 12.51, 'feels_like': 12.32, 'temp_min...   \n",
      "22  1716012000  {'temp': 12.96, 'feels_like': 12.84, 'temp_min...   \n",
      "23  1716022800  {'temp': 13.17, 'feels_like': 13.08, 'temp_min...   \n",
      "24  1716033600  {'temp': 13.98, 'feels_like': 13.89, 'temp_min...   \n",
      "25  1716044400  {'temp': 15.53, 'feels_like': 15.41, 'temp_min...   \n",
      "26  1716055200  {'temp': 14.93, 'feels_like': 14.88, 'temp_min...   \n",
      "27  1716066000  {'temp': 12.63, 'feels_like': 12.48, 'temp_min...   \n",
      "28  1716076800  {'temp': 11.74, 'feels_like': 11.48, 'temp_min...   \n",
      "29  1716087600  {'temp': 11.22, 'feels_like': 10.9, 'temp_min'...   \n",
      "30  1716098400  {'temp': 12.67, 'feels_like': 12.42, 'temp_min...   \n",
      "31  1716109200  {'temp': 15.23, 'feels_like': 14.9, 'temp_min'...   \n",
      "32  1716120000  {'temp': 20.3, 'feels_like': 19.69, 'temp_min'...   \n",
      "33  1716130800  {'temp': 20.03, 'feels_like': 19.47, 'temp_min...   \n",
      "34  1716141600  {'temp': 15.85, 'feels_like': 15.32, 'temp_min...   \n",
      "35  1716152400  {'temp': 12.15, 'feels_like': 11.74, 'temp_min...   \n",
      "36  1716163200  {'temp': 10.98, 'feels_like': 10.61, 'temp_min...   \n",
      "37  1716174000  {'temp': 9.7, 'feels_like': 8.41, 'temp_min': ...   \n",
      "38  1716184800  {'temp': 11.44, 'feels_like': 11.02, 'temp_min...   \n",
      "39  1716195600  {'temp': 16.17, 'feels_like': 15.8, 'temp_min'...   \n",
      "\n",
      "                                              weather        clouds  \\\n",
      "0   [{'id': 500, 'main': 'Rain', 'description': 'l...   {'all': 75}   \n",
      "1   [{'id': 500, 'main': 'Rain', 'description': 'l...   {'all': 83}   \n",
      "2   [{'id': 500, 'main': 'Rain', 'description': 'l...   {'all': 92}   \n",
      "3   [{'id': 500, 'main': 'Rain', 'description': 'l...  {'all': 100}   \n",
      "4   [{'id': 500, 'main': 'Rain', 'description': 'l...  {'all': 100}   \n",
      "5   [{'id': 500, 'main': 'Rain', 'description': 'l...   {'all': 99}   \n",
      "6   [{'id': 500, 'main': 'Rain', 'description': 'l...  {'all': 100}   \n",
      "7   [{'id': 500, 'main': 'Rain', 'description': 'l...  {'all': 100}   \n",
      "8   [{'id': 500, 'main': 'Rain', 'description': 'l...  {'all': 100}   \n",
      "9   [{'id': 500, 'main': 'Rain', 'description': 'l...  {'all': 100}   \n",
      "10  [{'id': 500, 'main': 'Rain', 'description': 'l...  {'all': 100}   \n",
      "11  [{'id': 500, 'main': 'Rain', 'description': 'l...   {'all': 99}   \n",
      "12  [{'id': 500, 'main': 'Rain', 'description': 'l...   {'all': 98}   \n",
      "13  [{'id': 804, 'main': 'Clouds', 'description': ...  {'all': 100}   \n",
      "14  [{'id': 804, 'main': 'Clouds', 'description': ...  {'all': 100}   \n",
      "15  [{'id': 804, 'main': 'Clouds', 'description': ...   {'all': 98}   \n",
      "16  [{'id': 804, 'main': 'Clouds', 'description': ...   {'all': 98}   \n",
      "17  [{'id': 500, 'main': 'Rain', 'description': 'l...  {'all': 100}   \n",
      "18  [{'id': 500, 'main': 'Rain', 'description': 'l...  {'all': 100}   \n",
      "19  [{'id': 500, 'main': 'Rain', 'description': 'l...  {'all': 100}   \n",
      "20  [{'id': 804, 'main': 'Clouds', 'description': ...  {'all': 100}   \n",
      "21  [{'id': 500, 'main': 'Rain', 'description': 'l...  {'all': 100}   \n",
      "22  [{'id': 500, 'main': 'Rain', 'description': 'l...  {'all': 100}   \n",
      "23  [{'id': 500, 'main': 'Rain', 'description': 'l...  {'all': 100}   \n",
      "24  [{'id': 500, 'main': 'Rain', 'description': 'l...  {'all': 100}   \n",
      "25  [{'id': 500, 'main': 'Rain', 'description': 'l...  {'all': 100}   \n",
      "26  [{'id': 500, 'main': 'Rain', 'description': 'l...  {'all': 100}   \n",
      "27  [{'id': 804, 'main': 'Clouds', 'description': ...  {'all': 100}   \n",
      "28  [{'id': 804, 'main': 'Clouds', 'description': ...  {'all': 100}   \n",
      "29  [{'id': 804, 'main': 'Clouds', 'description': ...   {'all': 98}   \n",
      "30  [{'id': 500, 'main': 'Rain', 'description': 'l...   {'all': 98}   \n",
      "31  [{'id': 804, 'main': 'Clouds', 'description': ...   {'all': 88}   \n",
      "32  [{'id': 803, 'main': 'Clouds', 'description': ...   {'all': 64}   \n",
      "33  [{'id': 802, 'main': 'Clouds', 'description': ...   {'all': 29}   \n",
      "34  [{'id': 803, 'main': 'Clouds', 'description': ...   {'all': 57}   \n",
      "35  [{'id': 802, 'main': 'Clouds', 'description': ...   {'all': 32}   \n",
      "36  [{'id': 801, 'main': 'Clouds', 'description': ...   {'all': 18}   \n",
      "37  [{'id': 801, 'main': 'Clouds', 'description': ...   {'all': 20}   \n",
      "38  [{'id': 802, 'main': 'Clouds', 'description': ...   {'all': 39}   \n",
      "39  [{'id': 803, 'main': 'Clouds', 'description': ...   {'all': 74}   \n",
      "\n",
      "                                         wind  visibility   pop          rain  \\\n",
      "0   {'speed': 1.15, 'deg': 161, 'gust': 1.72}       10000  1.00  {'3h': 0.32}   \n",
      "1    {'speed': 0.42, 'deg': 69, 'gust': 0.65}       10000  0.72  {'3h': 0.37}   \n",
      "2       {'speed': 1.55, 'deg': 64, 'gust': 2}       10000  0.27  {'3h': 0.23}   \n",
      "3    {'speed': 1.42, 'deg': 83, 'gust': 1.92}       10000  1.00  {'3h': 2.67}   \n",
      "4    {'speed': 2.03, 'deg': 70, 'gust': 3.02}       10000  1.00   {'3h': 1.6}   \n",
      "5    {'speed': 1.04, 'deg': 52, 'gust': 1.16}       10000  0.41  {'3h': 0.31}   \n",
      "6   {'speed': 0.77, 'deg': 299, 'gust': 0.97}       10000  0.36  {'3h': 0.18}   \n",
      "7   {'speed': 2.39, 'deg': 269, 'gust': 3.49}       10000  1.00  {'3h': 0.55}   \n",
      "8   {'speed': 2.25, 'deg': 252, 'gust': 2.95}       10000  1.00  {'3h': 0.69}   \n",
      "9   {'speed': 3.32, 'deg': 226, 'gust': 6.07}        9967  1.00   {'3h': 2.2}   \n",
      "10  {'speed': 2.01, 'deg': 288, 'gust': 3.81}        7320  1.00  {'3h': 1.48}   \n",
      "11  {'speed': 0.86, 'deg': 289, 'gust': 0.85}       10000  0.20  {'3h': 0.13}   \n",
      "12  {'speed': 0.92, 'deg': 275, 'gust': 1.01}       10000  0.20  {'3h': 0.25}   \n",
      "13  {'speed': 0.46, 'deg': 226, 'gust': 0.56}       10000  0.00           NaN   \n",
      "14  {'speed': 1.28, 'deg': 229, 'gust': 1.66}       10000  0.00           NaN   \n",
      "15   {'speed': 1.19, 'deg': 274, 'gust': 1.6}       10000  0.00           NaN   \n",
      "16   {'speed': 1.53, 'deg': 330, 'gust': 2.1}       10000  0.00           NaN   \n",
      "17   {'speed': 3.21, 'deg': 26, 'gust': 3.24}       10000  0.26  {'3h': 0.15}   \n",
      "18    {'speed': 2.39, 'deg': 7, 'gust': 4.35}       10000  0.52  {'3h': 0.42}   \n",
      "19   {'speed': 2.36, 'deg': 358, 'gust': 3.8}       10000  0.29  {'3h': 0.16}   \n",
      "20  {'speed': 2.22, 'deg': 341, 'gust': 3.68}       10000  0.00           NaN   \n",
      "21  {'speed': 2.17, 'deg': 341, 'gust': 4.67}       10000  1.00  {'3h': 0.73}   \n",
      "22    {'speed': 1.92, 'deg': 12, 'gust': 3.2}       10000  1.00  {'3h': 0.82}   \n",
      "23  {'speed': 0.71, 'deg': 110, 'gust': 1.36}       10000  1.00  {'3h': 2.03}   \n",
      "24  {'speed': 1.17, 'deg': 339, 'gust': 1.53}       10000  1.00   {'3h': 1.6}   \n",
      "25  {'speed': 3.13, 'deg': 359, 'gust': 3.54}       10000  0.62  {'3h': 0.27}   \n",
      "26  {'speed': 1.81, 'deg': 338, 'gust': 2.94}       10000  0.92  {'3h': 0.52}   \n",
      "27  {'speed': 1.98, 'deg': 313, 'gust': 2.46}       10000  0.00           NaN   \n",
      "28  {'speed': 2.14, 'deg': 313, 'gust': 2.89}       10000  0.00           NaN   \n",
      "29  {'speed': 1.44, 'deg': 280, 'gust': 1.04}       10000  0.00           NaN   \n",
      "30   {'speed': 1.78, 'deg': 351, 'gust': 3.2}       10000  0.20  {'3h': 0.17}   \n",
      "31   {'speed': 2.25, 'deg': 18, 'gust': 3.54}       10000  0.00           NaN   \n",
      "32   {'speed': 4.11, 'deg': 10, 'gust': 4.84}       10000  0.00           NaN   \n",
      "33  {'speed': 6.17, 'deg': 357, 'gust': 6.11}       10000  0.00           NaN   \n",
      "34  {'speed': 3.76, 'deg': 356, 'gust': 7.73}       10000  0.00           NaN   \n",
      "35    {'speed': 3.37, 'deg': 5, 'gust': 7.55}       10000  0.00           NaN   \n",
      "36   {'speed': 3.02, 'deg': 20, 'gust': 6.65}       10000  0.00           NaN   \n",
      "37   {'speed': 2.59, 'deg': 18, 'gust': 5.08}       10000  0.00           NaN   \n",
      "38   {'speed': 3.24, 'deg': 32, 'gust': 4.88}       10000  0.00           NaN   \n",
      "39   {'speed': 3.46, 'deg': 47, 'gust': 4.44}       10000  0.00           NaN   \n",
      "\n",
      "             sys               dt_txt  \n",
      "0   {'pod': 'd'}  2024-05-15 12:00:00  \n",
      "1   {'pod': 'd'}  2024-05-15 15:00:00  \n",
      "2   {'pod': 'd'}  2024-05-15 18:00:00  \n",
      "3   {'pod': 'n'}  2024-05-15 21:00:00  \n",
      "4   {'pod': 'n'}  2024-05-16 00:00:00  \n",
      "5   {'pod': 'n'}  2024-05-16 03:00:00  \n",
      "6   {'pod': 'd'}  2024-05-16 06:00:00  \n",
      "7   {'pod': 'd'}  2024-05-16 09:00:00  \n",
      "8   {'pod': 'd'}  2024-05-16 12:00:00  \n",
      "9   {'pod': 'd'}  2024-05-16 15:00:00  \n",
      "10  {'pod': 'd'}  2024-05-16 18:00:00  \n",
      "11  {'pod': 'n'}  2024-05-16 21:00:00  \n",
      "12  {'pod': 'n'}  2024-05-17 00:00:00  \n",
      "13  {'pod': 'n'}  2024-05-17 03:00:00  \n",
      "14  {'pod': 'd'}  2024-05-17 06:00:00  \n",
      "15  {'pod': 'd'}  2024-05-17 09:00:00  \n",
      "16  {'pod': 'd'}  2024-05-17 12:00:00  \n",
      "17  {'pod': 'd'}  2024-05-17 15:00:00  \n",
      "18  {'pod': 'd'}  2024-05-17 18:00:00  \n",
      "19  {'pod': 'n'}  2024-05-17 21:00:00  \n",
      "20  {'pod': 'n'}  2024-05-18 00:00:00  \n",
      "21  {'pod': 'n'}  2024-05-18 03:00:00  \n",
      "22  {'pod': 'd'}  2024-05-18 06:00:00  \n",
      "23  {'pod': 'd'}  2024-05-18 09:00:00  \n",
      "24  {'pod': 'd'}  2024-05-18 12:00:00  \n",
      "25  {'pod': 'd'}  2024-05-18 15:00:00  \n",
      "26  {'pod': 'd'}  2024-05-18 18:00:00  \n",
      "27  {'pod': 'n'}  2024-05-18 21:00:00  \n",
      "28  {'pod': 'n'}  2024-05-19 00:00:00  \n",
      "29  {'pod': 'n'}  2024-05-19 03:00:00  \n",
      "30  {'pod': 'd'}  2024-05-19 06:00:00  \n",
      "31  {'pod': 'd'}  2024-05-19 09:00:00  \n",
      "32  {'pod': 'd'}  2024-05-19 12:00:00  \n",
      "33  {'pod': 'd'}  2024-05-19 15:00:00  \n",
      "34  {'pod': 'd'}  2024-05-19 18:00:00  \n",
      "35  {'pod': 'n'}  2024-05-19 21:00:00  \n",
      "36  {'pod': 'n'}  2024-05-20 00:00:00  \n",
      "37  {'pod': 'n'}  2024-05-20 03:00:00  \n",
      "38  {'pod': 'd'}  2024-05-20 06:00:00  \n",
      "39  {'pod': 'd'}  2024-05-20 09:00:00  \n"
     ]
    }
   ],
   "source": [
    "# function to call the openweather API and store in a dataframe\n",
    "def get_forecast():\n",
    "    # Call the API\n",
    "    data = call_open_weather_api(url_forecast)\n",
    "    # Check if the data is correct\n",
    "    if data:\n",
    "        df = pd.DataFrame(data[\"list\"])\n",
    "        return df\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "print(get_forecast())\n",
    "\n",
    "\n",
    "# function to get the forecast data\n",
    "def get_forecast_data():\n",
    "    # Call the API\n",
    "    df = get_forecast()\n",
    "    # Check if the data is correct and return the necessary columns\n",
    "    if df is not None:\n",
    "        df = df[[\"dt_txt\", \"main\", \"weather\", \"clouds\", \"wind\", \"pop\"]]\n",
    "        return df\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to Call all the forecast data and analize relevance, pertinence, and processing needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion to get the forecast data and store it in a dataframe\n",
    "def get_forecast_data():\n",
    "    data = call_open_weather_api(url_forecast)\n",
    "    if data is not None:\n",
    "        df = pd.json_normalize(data[\"list\"])\n",
    "        # df = df[['dt','dt_txt','main.temp','main.humidity','wind.speed','clouds.all','main.grnd_level', 'rain.3h']]\n",
    "        # df.columns = ['dt','date','temperature','humidity','windSpeed','cloudCover','pressure','rain']\n",
    "        # from weather column keep only 'id'\n",
    "        df[\"weather\"] = df[\"weather\"].apply(lambda x: x[0][\"id\"])\n",
    "\n",
    "        return df\n",
    "\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "print(get_forecast_data().info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop forseveral points\n",
    "Function to integrate in the call different sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to iterate thru a list of sites and get the forecast data, store it in a dataframe and save it in a csv file:\n",
    "\n",
    "\n",
    "def get_forecast_data():\n",
    "    # create df_forecast to store the data\n",
    "    df_forecast = pd.DataFrame()\n",
    "    # create df_lat_lon and use data/lat_long_cities.csv (path_lat_lon)\n",
    "    df_lat_lon = pd.read_csv(path_lat_lon)\n",
    "    # Create a call with each one of the df_lat_lon rows and store the data in df_forecast\n",
    "    for index, row in df_lat_lon.iterrows():\n",
    "        lat = row[\"Latitude\"]\n",
    "        lon = row[\"Latitude\"]\n",
    "        url_forecast = (\n",
    "            \"https://api.openweathermap.org/data/2.5/forecast?lat=\"\n",
    "            + str(lat)\n",
    "            + \"&lon=\"\n",
    "            + str(lon)\n",
    "            + \"&appid=\"\n",
    "            + API_KEY\n",
    "            + \"&units=metric\"\n",
    "        )\n",
    "        data = call_open_weather_api(url_forecast)\n",
    "        if data is not None:\n",
    "            df = pd.json_normalize(data[\"list\"])\n",
    "            df[\"lat\"] = lat\n",
    "            df[\"lon\"] = lon\n",
    "            df_forecast = pd.concat([df_forecast, df], ignore_index=True)\n",
    "    # # store the data using the store_data function\n",
    "    # store_data(df_forecast, path_forecast_data)\n",
    "    return df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_forecast_data().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stable version of the API call before save to csv and create DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call the Openweather API one city\n",
    "\"\"\"\n",
    "Function to call the call_openweather_api(urm),\n",
    "get the data and store it in a dataframe and append to csv file\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_weather_forecast():\n",
    "\n",
    "    data = call_open_weather_api(url_forecast)\n",
    "\n",
    "    if data is not None:\n",
    "\n",
    "        df = pd.json_normalize(data[\"list\"])\n",
    "\n",
    "        # Add the new data with a timestamp of the time of the request\n",
    "        df[\"timestamp\"] = pd.Timestamp.now()\n",
    "\n",
    "        # Convert the weather column to a single value\n",
    "        df[\"weather\"] = df[\"weather\"].apply(lambda x: x[0][\"id\"])\n",
    "\n",
    "        # define the columns to keep and rename them\n",
    "        df = df[\n",
    "            [\n",
    "                \"timestamp\",\n",
    "                \"dt_txt\",\n",
    "                \"weather\",\n",
    "                \"main.temp\",\n",
    "                \"main.humidity\",\n",
    "                \"wind.speed\",\n",
    "                \"clouds.all\",\n",
    "                \"main.grnd_level\",\n",
    "                \"rain.3h\",\n",
    "            ]\n",
    "        ]\n",
    "        df.columns = [\n",
    "            \"timestamp\",\n",
    "            \"date\",  # change to date_time_utc for the final version\n",
    "            \"weather_score\",\n",
    "            \"temperature\",\n",
    "            \"humidity\",\n",
    "            \"windSpeed\",\n",
    "            \"cloudCover\",\n",
    "            \"pressure\",\n",
    "            \"rain\",\n",
    "        ]\n",
    "        # add the coord.lat - coord.lon from data['city']\n",
    "        df[\"lat\"] = data[\"city\"][\"coord\"][\"lat\"]\n",
    "        df[\"lon\"] = data[\"city\"][\"coord\"][\"lon\"]\n",
    "\n",
    "        # replace \"lat\" and \"lon\" with the actual values\n",
    "        df[\"lat\"] = lat\n",
    "        df[\"lon\"] = lon\n",
    "\n",
    "        # if empty space in the rain column, replace with 0\n",
    "        df[\"rain\"] = df[\"rain\"].fillna(0)\n",
    "\n",
    "        # insert the data into the csv file\n",
    "        if pathlib.Path(path_forecast_csv).exists():\n",
    "            df.to_csv(path_forecast_csv, mode=\"a\", header=False, index=False)\n",
    "        else:\n",
    "            df.to_csv(path_forecast_csv, mode=\"w\", header=True, index=False)\n",
    "\n",
    "        return df\n",
    "\n",
    "    else:\n",
    "\n",
    "        return None\n",
    "\n",
    "    # to improve: handle errors and exceptions\n",
    "    # connection error, file not found, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to automate inoput data every x minutes\n",
    "Recurrent function to be automatised and executed with regularity to updated data regularly for the site\n",
    "- time_api_call: time in minutes to parameter the regularity of the automatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a schedule to run the get_weather_forecast function every 15 minutes\n",
    "def automate_forecast():\n",
    "    # start time\n",
    "    start_time_automate = time.time()\n",
    "    schedule.every(up_time).minutes.do(get_weather_forecast)\n",
    "    while True:\n",
    "        schedule.run_pending()\n",
    "        time.sleep(1)\n",
    "        # end time\n",
    "        end_time_automate = time.time()\n",
    "        print(\"Execution time: \", end_time_automate - start_time_automate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to use the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area to call funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_forecast()\n",
    "\n",
    "# data_forecast = call_open_weather_api(url_forecast)\n",
    "\n",
    "# data_forecast\n",
    "\n",
    "# get_weather_forecast()\n",
    "\n",
    "automate_forecast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # From data create a data frame with 'temp'\n",
    "# df_forecast_full = pd.json_normalize(data_forecast['list'])\n",
    "# df_forecast_city = pd.json_normalize(data_forecast['city'])\n",
    "# df_forecast_full.head()\n",
    "# df_forecast_city.tail()\n",
    "# df_forecast = df_forecast_full[['dt_txt','main.temp','main.humidity','wind.speed','clouds.all','main.grnd_level', 'rain.3h']]\n",
    "# df_forecast.columns = ['date','temperature','humidity','windSpeed','cloudCover','pressure','rain']\n",
    "# df_forecast.head()\n",
    "# df_forecast_full['weather']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the value of column weather first row\n",
    "print(df[\"weather\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify that the data downlodesd is ok\n",
    "- Function to verfy that there is not error or empty values in the data before to send to timeseries\n",
    "\n",
    "# To solve\n",
    "- each fucntion should have thier own url variable, to target the specific needs (ok)\n",
    "- Function get_weather should be executed every 15 minutes, starting from 00:00 every day\n",
    "    - possile solution, create and automation that start at 00:00 for the automation that call the api every 15 minutes **Cron schedule in zapdos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to wrangle df\n",
    "# def post_processing():\n",
    "#     # Replace missing values with 0 in column: 'rain'\n",
    "#     df = df.fillna({\"rain\": 0})\n",
    "\n",
    "#     # Performed 10 aggregations grouped on column: 'date'\n",
    "#     df = (\n",
    "#         df.groupby([\"date\"])\n",
    "#         .agg(\n",
    "#             timestamp_last=(\"timestamp\", \"last\"),\n",
    "#             weather_score_mode=(\"weather_score\", lambda s: s.value_counts().index[0]),\n",
    "#             temperature_mean=(\"temperature\", \"mean\"),\n",
    "#             humidity_mean=(\"humidity\", \"mean\"),\n",
    "#             windSpeed_mean=(\"windSpeed\", \"mean\"),\n",
    "#             cloudCover_mean=(\"cloudCover\", \"mean\"),\n",
    "#             pressure_mode=(\"pressure\", lambda s: s.value_counts().index[0]),\n",
    "#             rain_mean=(\"rain\", \"mean\"),\n",
    "#             lat_mean=(\"lat\", \"mean\"),\n",
    "#             lon_mean=(\"lon\", \"mean\"),\n",
    "#         )\n",
    "#         .reset_index()\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zapdos-_kYdOZQc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
